{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc4741b-a14c-40fd-9ac0-a3bd07633747",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building  Text-to-SQL capability to Amazon Athena using Amazon Bedrock\n",
    "\n",
    "- **Use of amazon.titan-embed-text-v1 for creating embedding**\n",
    "- **Use of Amazon OpenSearch as a vector database**\n",
    "- **Use of anthropic.claude-v2:1 as base LLM Model**\n",
    "\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Objective](#Objective)\n",
    "1. [Background](#Background-(Problem-Description-and-Approach))\n",
    "1. [Overall Workflow](#Overall-Workflow)\n",
    "1. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5453ed1-3da0-4c03-a376-e90e06c8a7eb",
   "metadata": {},
   "source": [
    "\n",
    "## Objective\n",
    "\n",
    "This notebook shows how to leverage Bedrock to invoke an LLM that can convert natural language inputs to SQL queries. The LLM-generated SQL is then executed using Athena.\n",
    "\n",
    "## Background (Problem Description and Approach)\n",
    "\n",
    "- **Problem statement**: \n",
    "\n",
    "Using LLMs for information retrieval tasks (such as question-answering) requires converting the knowledge corpus as well as user questions into vector embeddings. We want to generate these vector embeddings using an LLM \n",
    "\n",
    "Here for small metadata we have used  For converting large amounts of data (TBs or PBs) we need a scalable system which can accomplish both converting the documents into embeddings, storing them in a vector database and provide low latency similarity search\n",
    "\n",
    "- **Our approach**: \n",
    "\n",
    "[`RAG`]The RAG approach offers several advantages. First, it gives up-to-date, precise responses. Rather than relying only on fixed, outdated training data, RAG utilizes current external sources to formulate its answers.\n",
    "\n",
    "[`Vector Store`] Amazon OpenSearch offers three vector engines to choose from, each catering to different use cases.Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors.This code bases used FAISS for similiarity search.\n",
    "\n",
    "[`Bedrock`] Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Stability AI, and Amazon via a single API, along with a broad set of capabilities you need to build generative AI applications with security, privacy, and responsible AI.\n",
    "\n",
    "- *[The langchain OpenSearch documentation](https://python.langchain.com/en/latest/ecosystem/opensearch.html)*\n",
    "- *[Amazon OpenSearch service documentation](https://docs.aws.amazon.com/opensearch-service/index.html)*\n",
    "- *[Amazon OpenSearch supports efficient vector](https://aws.amazon.com/about-aws/whats-new/2023/10/amazon-opensearch-service-vector-query-filters-faiss/)*\n",
    "- *[Amazon Bedrock](https://aws.amazon.com/bedrock/)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e68cc7-f452-4c88-9b49-4c10b069ce0c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overall Workflow\n",
    "\n",
    "**Prerequisite**\n",
    "\n",
    "The following are prerequisites that needs to be accomplised before executing this notebook.\n",
    "- A Sagemaker instance with a role having access to bedrock, glue,athena,s3,lakeformation\n",
    "- Glue Database and tables. Provided spark notebook to create.\n",
    "- An Amazon OpenSearch cluster for storing embeddings.Here Opensearch credenitals are in notebooks. However Opensearch cluster's access credentials (username and password) can be stored in AWS Secrets Mananger by following steps described [here](https://docs.aws.amazon.com/secretsmanager/latest/userguide/managing-secrets.html).\n",
    "\n",
    "**The overall workflow for this notebook is as follows:**\n",
    "1. Download data from source https://developer.imdb.com/non-commercial-datasets/#titleakastsvgz and upload to S3.\n",
    "1. Create database and load datasets in Glue. Make sure see of the you are able to query through athena. \n",
    "1. Install the required Python packages (specifically boto version mentioned)\n",
    "1. Create embedding and vector store.Do a similarity search with embeddings stored in the OpenSearch index for an input query.\n",
    "1. Execute this notebook to generate sql.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994fd3e5-416d-4e4a-bfaf-faad2b53dc0c",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3af34-9c4b-4e95-9147-cf498a74a0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install boto3==1.34.8\n",
    "# !pip3 install jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f072e-88b1-4afc-ba4a-daa49f05bcd8",
   "metadata": {},
   "source": [
    "## Step 2: Import all modules. There are some modules in other folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987d606c-5200-462b-8cce-ec377760361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.embeddings import BedrockEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef96ac35-3597-4bd8-80ca-035c6c98050b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging \n",
    "import json\n",
    "import os,sys\n",
    "import re\n",
    "sys.path.append(\"/home/ec2-user/SageMaker/llm_bedrock_v0/\")\n",
    "import time\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a246f1d8-b941-4594-a879-abd2d0dc5eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from boto_client import Clientmodules\n",
    "from llm_basemodel import LanguageModel\n",
    "from athena_execution import AthenaQueryExecute\n",
    "from vector_embedding import EmbeddingBedrock\n",
    "from openSearchVCEmbedding import EmbeddingBedrockOpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03e654e-024f-4837-82d1-7f277344c46f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6d68a-cf48-4b7f-94c5-418f2cc8f44a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3:Checking access to Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436fb4f1-cd34-4146-bc96-da5e3608d720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 00:10:25,506,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large', 'modelId': 'amazon.titan-tg1-large', 'modelName': 'Titan Text Large', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n"
     ]
    }
   ],
   "source": [
    "session = boto3.session.Session()\n",
    "bedrock_client = session.client('bedrock')\n",
    "print(bedrock_client.list_foundation_models()['modelSummaries'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2217e5-dc53-428f-b224-fb3ac9e8f952",
   "metadata": {},
   "source": [
    "## Step 4:Invoking athena and bedrock embedding utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e44bd9-8787-447a-b5e0-0961547bafef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 00:10:25,658,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "athena client created \n",
      "2024-01-15 00:10:25,696,boto_client,MainProcess,INFO,athena client created \n",
      "2024-01-15 00:10:25,711,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "s3 client created !!\n",
      "2024-01-15 00:10:25,775,boto_client,MainProcess,INFO,s3 client created !!\n"
     ]
    }
   ],
   "source": [
    "rqstath=AthenaQueryExecute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44de454e-058d-4b52-bd52-a8c573c9a963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 00:10:25,875,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "bedrock runtime client created \n",
      "2024-01-15 00:10:26,027,boto_client,MainProcess,INFO,bedrock runtime client created \n"
     ]
    }
   ],
   "source": [
    "ebr=EmbeddingBedrock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9ff739-430d-41f4-85b9-045dfaed0d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 00:10:26,594,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "bedrock runtime client created \n",
      "2024-01-15 00:10:26,628,boto_client,MainProcess,INFO,bedrock runtime client created \n"
     ]
    }
   ],
   "source": [
    "ebropen=EmbeddingBedrockOpenSearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73833ad4-d3e0-46a5-acd0-2e112e23fcc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 5: Core logic\n",
    "1. getEmbeddding : Take the input user query and vector search to find the schema from vector db created.\n",
    "2. generate_sql: Taking the input prompt, generate sql . syntax_checker helps to check the sql syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdcd87a9-f028-43ab-94a4-8d9b5b5bd163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RequestQueryBedrock:\n",
    "    def __init__(self):\n",
    "        # self.model_id = \"anthropic.claude-v2\"\n",
    "        self.bedrock_client = Clientmodules.createBedrockRuntimeClient()\n",
    "        self.language_model = LanguageModel(self.bedrock_client)\n",
    "        self.llm = self.language_model.llm\n",
    "    def getEmbeddding(self,user_question):\n",
    "        vector_store_path=os.getcwd()+'/'+'vectorstore/'+ '03012024225156.vs'\n",
    "        print(\"vector_store_path :\",vector_store_path)\n",
    "        vs=ebr.load_local_vector_store(vector_store_path)\n",
    "        required_metadata = vs.similarity_search_with_score(user_question)\n",
    "        docs, scores = zip(*required_metadata)\n",
    "        return ebr.format_metadata(docs)\n",
    "    def getOpenSearchEmbedding(self,index_name,user_query):\n",
    "        vcindxdoc=ebropen.getDocumentfromIndex(index_name=index_name)\n",
    "        documnet=ebropen.getSimilaritySearch(user_query,vcindxdoc)\n",
    "        return ebropen.format_metadata(documnet)\n",
    "        \n",
    "    def generate_sql(self,prompt, max_attempt=4) ->str:\n",
    "            \"\"\"\n",
    "            Generate and Validate SQL query.\n",
    "\n",
    "            Args:\n",
    "            - prompt (str): Prompt is user input and metadata from Rag to generating SQL.\n",
    "            - max_attempt (int): Maximum number of attempts correct the syntax SQL.\n",
    "\n",
    "            Returns:\n",
    "            - string: Sql query is returned .\n",
    "            \"\"\"\n",
    "            attempt = 0\n",
    "            error_messages = []\n",
    "            prompts = [prompt]\n",
    "\n",
    "            while attempt < max_attempt:\n",
    "                logger.info(f'Sql Generation attempt Count: {attempt+1}')\n",
    "                try:\n",
    "                    logger.info(f'we are in Try block to generate the sql and count is :{attempt+1}')\n",
    "                    generated_sql = self.llm.predict(prompt)\n",
    "                    query_str = generated_sql.split(\"```\")[1]\n",
    "                    query_str = \" \".join(query_str.split(\"\\n\")).strip()\n",
    "                    sql_query = query_str[3:] if query_str.startswith(\"sql\") else query_str\n",
    "                    # return sql_query\n",
    "                    syntaxcheckmsg=rqstath.syntax_checker(sql_query)\n",
    "                    if syntaxcheckmsg=='Passed':\n",
    "                        logger.info(f'syntax checked for query passed in attempt number :{attempt+1}')\n",
    "                        return sql_query\n",
    "                    else:\n",
    "                        prompt = f\"\"\"{prompt}\n",
    "                        This is syntax error: {syntaxcheckmsg}. \n",
    "                        To correct this, please generate an alternative SQL query which will correct the syntax error.\n",
    "                        The updated query should take care of all the syntax issues encountered.\n",
    "                        Follow the instructions mentioned above to remediate the error. \n",
    "                        Update the below SQL query to resolve the issue:\n",
    "                        {sqlgenerated}\n",
    "                        Make sure the updated SQL query aligns with the requirements provided in the initial question.\"\"\"\n",
    "                        prompts.append(prompt)\n",
    "                        attempt += 1\n",
    "                except Exception as e:\n",
    "                    logger.error('FAILED')\n",
    "                    msg = str(e)\n",
    "                    error_messages.append(msg)\n",
    "                    attempt += 1\n",
    "            return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13da2f51-6032-4564-8943-3c36e55b025f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 00:10:28,158,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "bedrock runtime client created \n",
      "2024-01-15 00:10:28,191,boto_client,MainProcess,INFO,bedrock runtime client created \n"
     ]
    }
   ],
   "source": [
    "rqst=RequestQueryBedrock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "552419cd-3827-41ee-9aab-ca93c756b9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = 'llm_vector_db_metadata_indx2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6b4e5f-b52e-4209-aab7-403dabc61239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def userinput(user_query):\n",
    "    logger.info(f'Searching metadata from vector store')\n",
    "    # vector_search_match=rqst.getEmbeddding(user_query)\n",
    "    vector_search_match=rqst.getOpenSearchEmbedding(index_name,user_query)\n",
    "    # print(vector_search_match)\n",
    "    details=\"It is important that the SQL query complies with Athena syntax. During join if column name are same please use alias ex llm.customer_id in select statement. It is also important to respect the type of columns: if a column is string, the value should be enclosed in quotes. If you are writing CTEs then include all the required columns. While concatenating a non string column, make sure cast the column to string. For date columns comparing to string , please cast the string input.\"\n",
    "    final_question = \"\\n\\nHuman:\"+details + vector_search_match + user_query+ \"n\\nAssistant:\"\n",
    "    answer = rqst.generate_sql(final_question)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ebe772-af08-4df5-b950-3d6aa35dd1cb",
   "metadata": {},
   "source": [
    "## Step 6: User input in Natular Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d5b62a-4446-43d2-a4bf-6d51061160a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_query='show me all the title in US region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c519a069-6874-4b30-9b54-ad7bdf548840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching metadata from vector store\n",
      "2024-01-15 00:17:48,805,1460622309,MainProcess,INFO,Searching metadata from vector store\n",
      "2024-01-15 00:17:49,716,base,MainProcess,INFO,POST https://search-llm-vectordb-1-jsdrnnhchl6rsh7s4biqregpuq.us-east-1.es.amazonaws.com:443/llm_vector_db_metadata_indx2/_search [status:200 request:0.536s]\n",
      "Sql Generation attempt Count: 1\n",
      "2024-01-15 00:17:49,718,1749336078,MainProcess,INFO,Sql Generation attempt Count: 1\n",
      "we are in Try block to generate the sql and count is :1\n",
      "2024-01-15 00:17:49,719,1749336078,MainProcess,INFO,we are in Try block to generate the sql and count is :1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Explain   WITH titles AS (   SELECT title, region   FROM imdb_stg.title ) SELECT title  FROM titles WHERE region = 'US'\n",
      " I am checking the syntax here\n",
      "execution_id: d545d657-cc67-45e1-8b5a-f5c98a4a2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "syntax checked for query passed in attempt number :1\n",
      "2024-01-15 00:18:00,317,1749336078,MainProcess,INFO,syntax checked for query passed in attempt number :1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status : {'State': 'SUCCEEDED', 'SubmissionDateTime': datetime.datetime(2024, 1, 15, 0, 17, 57, 260000, tzinfo=tzlocal()), 'CompletionDateTime': datetime.datetime(2024, 1, 15, 0, 17, 57, 873000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "querygenerated=userinput(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ee907-5f0e-4b3d-93f7-3f8b4e048555",
   "metadata": {},
   "source": [
    "## Step 7: Sql Query and Query Execution output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d419b600-f612-47c1-8064-01c111193ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' WITH titles AS (   SELECT title, region   FROM imdb_stg.title ) SELECT '\n",
      " \"title  FROM titles WHERE region = 'US'\")\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "my_printer = pprint.PrettyPrinter()\n",
    "my_printer.pprint(querygenerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aeebd48-dd41-4ff7-8803-2bb1d46b4607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checking for file :athena_output/f593ee48-788f-4efa-a689-c4b02f82ed3d.csv\n",
      "2024-01-15 00:20:34,510,athena_execution,MainProcess,INFO,checking for file :athena_output/f593ee48-788f-4efa-a689-c4b02f82ed3d.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling download fine with params /tmp/athena_output/f593ee48-788f-4efa-a689-c4b02f82ed3d.csv, {'OutputLocation': 's3://llm-athena-output/athena_output'}\n"
     ]
    }
   ],
   "source": [
    "QueryOutput=rqstath.execute_query(querygenerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf48663-4cb5-4e88-99c1-433d5e7b5754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     title\n",
      "0                                    This Is Parris Island\n",
      "1                                        Genius obsessions\n",
      "2                                             Carpe Duorum\n",
      "3                                         Blatantly Bianka\n",
      "4                                              FilmFrights\n",
      "...                                                    ...\n",
      "1490529                                   The White Orchid\n",
      "1490530                                        The Oficina\n",
      "1490531  State of Origin Australian Rules Football 1992...\n",
      "1490532  Riot Games Calls League of Legends Fans 'Manba...\n",
      "1490533                                         Endangered\n",
      "\n",
      "[1490534 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(QueryOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98397d4d-9b97-4c72-8763-f2247e88cd01",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Cleanup\n",
    "\n",
    "To avoid incurring future charges, delete the resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa1ade-7993-4348-a0f6-c511f1a797e7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook we were able to see how to use bedrock to deploy LLM Model to generate embeddings,then ingest those embeddings into OpenSearch and finally do a similarity search for user input to the documents (embeddings) stored in OpenSearch. We used langchain as an abstraction layer to do workflow management. Claude model us used to create sql and athena for query execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301c1f1-53f1-489c-ad42-8c57cd105352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
